---
title: The Quiz (Part 1)
author: Martin Rydén
date: '2020-06-26'
slug: the-quiz-part-1
categories: []
tags:
  - how-to
  - programming
  - R
  - web-scraping
  - wikipedia
  - data-mining
  - statistics
description: ''
featured_image: ''

---



<div id="preface" class="section level3">
<h3>Preface</h3>
<p>Imagine for a moment that you are interested in knowing the molecular function of some well-studied extracellular matrix proteins (don’t leave yet). Some would suggest that we’d find out by simply opening a book. Others would argue that we should simply <em>open Rstudio</em>.</p>
<p>But how will we put our knowledge to the test? The answer – is with a quiz.</p>
</div>
<div id="objective" class="section level3">
<h3>Objective</h3>
<p>Given a list of protein names, describe their molecular function using a data-mining approach. The collected data will be used in Part 2 when we construct a quiz.</p>
</div>
<div id="terminology" class="section level3">
<h3>Terminology</h3>
<table>
<thead>
<tr class="header">
<th align="left">Term</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">%&gt;%</td>
<td align="left">Tidyverse pipe operator that “forwards” an object to an expression</td>
</tr>
<tr class="even">
<td align="left">rvest</td>
<td align="left">R package for easy web scraping</td>
</tr>
<tr class="odd">
<td align="left">scraping</td>
<td align="left">Data extraction/mining from websites</td>
</tr>
<tr class="even">
<td align="left">read_html</td>
<td align="left">Given a url, reads html content</td>
</tr>
<tr class="odd">
<td align="left">xpath</td>
<td align="left">Specifies specific parts of html</td>
</tr>
<tr class="even">
<td align="left">html_nodes</td>
<td align="left">Extracts specific parts of html</td>
</tr>
<tr class="odd">
<td align="left">grep</td>
<td align="left">Pattern matching command</td>
</tr>
<tr class="even">
<td align="left">gsub</td>
<td align="left">Substitutes text matched by pattern</td>
</tr>
</tbody>
</table>
</div>
<div id="part-1---gathering-data" class="section level3">
<h3>Part 1 - Gathering data</h3>
<div id="wikipedia-scraping" class="section level4">
<h4>Wikipedia scraping</h4>
<p>Our inital source of information will be <em>the</em> source of information, Wikipedia.</p>
<p><a href="https://en.wikipedia.org/wiki/Category:Extracellular_matrix_proteins" class="uri">https://en.wikipedia.org/wiki/Category:Extracellular_matrix_proteins</a></p>
<iframe width="700" height="500" scrolling="yes" frameborder="yes" src="https://en.wikipedia.org/wiki/Category:Extracellular_matrix_proteins#mw-pages">
</iframe>
<p>We’ll begin by extracting the above list of protein names, and assemble them (and their urls) into a dataframe.</p>
<pre class="r"><code>library(data.table) # For data transformation / reshaping
library(tidyverse)  # For data transformation / reshaping
library(rvest)      # For web scraping
library(purrr)      # For map_df function
library(knitr)      # For table output

wurl &lt;- &#39;https://en.wikipedia.org/wiki/Category:Extracellular_matrix_proteins&#39;

# Using the above url, read html and select specific nodes*.
wnodes &lt;- wurl %&gt;%
    read_html %&gt;%
    html_nodes(xpath = &#39;//*[@id=&quot;mw-pages&quot;]/div/div/div&#39;)

# Given a nodeset: select list &lt;li&gt; tags,
# then select title (title) and url (href) attributes of &lt;a&gt; tags.
get_wiki_list &lt;- function(nodes) {
    nodes %&gt;%
        html_nodes(&quot;ul &gt; li&quot;) %&gt;%
        map_df(~{
            tibble(
                title = html_nodes(.x, &#39;a&#39;) %&gt;% html_attr(&#39;title&#39;),
                link = html_nodes(.x, &#39;a&#39;) %&gt;% html_attr(&#39;href&#39;)
            )
        }) -&gt; wl
    
    return(wl)
}

# Iterate over nodes (html elements for each protein) and fetch their title and link
wikitable &lt;- sapply(wnodes, get_wiki_list, USE.NAMES = F, simplify = F) %&gt;% bind_rows()

# Display first 10 entries
kable(head(wikitable))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="left">link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Aggrecan</td>
<td align="left">/wiki/Aggrecan</td>
</tr>
<tr class="even">
<td align="left">Agrin</td>
<td align="left">/wiki/Agrin</td>
</tr>
<tr class="odd">
<td align="left">Aspein</td>
<td align="left">/wiki/Aspein</td>
</tr>
<tr class="even">
<td align="left">Asporin</td>
<td align="left">/wiki/Asporin</td>
</tr>
<tr class="odd">
<td align="left">Biglycan</td>
<td align="left">/wiki/Biglycan</td>
</tr>
<tr class="even">
<td align="left">BMP binding endothelial regulator</td>
<td align="left">/wiki/BMP_binding_endothelial_regulator</td>
</tr>
</tbody>
</table>
<p>Neat. We have the protein names and their corresponding wiki urls.</p>
<p>What’s next?</p>
<p>We will “visit” each wiki page and, if possible, fetch <em>another url</em> - one that leads to <strong>UniProt</strong>; a comprehensive protein knowledgebase.</p>
<pre class="r"><code># Wikipedia base url
wikiurl &lt;- &#39;https://en.wikipedia.org&#39;

# For each protein in wikitable, scrape wiki article and fetch UniProt url
get_uniprot_links &lt;- function(wprot){
    
    # Get absolute url to article page
    wlink &lt;- paste0(wikiurl, wprot[&quot;link&quot;])
    
    # Read article html
    wtext &lt;- read_html(wlink)
    
    # Find the article&#39;s &quot;infobox&quot;
    infobox &lt;- html_nodes(wtext, xpath=&#39;//table[contains(@class, &quot;infobox&quot;)]//a&#39;)
    
    # If we can&#39;t find an infobox, just try to find uniprot.org url anywhere on page.
    if(is_empty(infobox)){
        up &lt;- grep(&quot;uniprot.org&quot;, html_nodes(wtext, &quot;a&quot;), value = T)
        if(length(up) == 0) {
            return(NA)
        } else {
            up %&gt;%
                as_xml_document() %&gt;%
                html_attr(&#39;href&#39;)
        }
    } else {
        # If we *do* find the infobox, find &quot;UniProt&quot; and get the url in the next cell (hence + 1)
        infobox[ grep(&quot;UniProt&quot;, infobox) + 1 ] %&gt;% html_attr(&#39;href&#39;)
    }
}

wikitable$uniprot &lt;- apply(wikitable, 1, get_uniprot_links)

kable(head(wikitable))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="left">link</th>
<th align="left">uniprot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Aggrecan</td>
<td align="left">/wiki/Aggrecan</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/P16112" class="uri">https://www.uniprot.org/uniprot/P16112</a></td>
</tr>
<tr class="even">
<td align="left">Agrin</td>
<td align="left">/wiki/Agrin</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/O00468" class="uri">https://www.uniprot.org/uniprot/O00468</a></td>
</tr>
<tr class="odd">
<td align="left">Aspein</td>
<td align="left">/wiki/Aspein</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/Q76K52" class="uri">https://www.uniprot.org/uniprot/Q76K52</a></td>
</tr>
<tr class="even">
<td align="left">Asporin</td>
<td align="left">/wiki/Asporin</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/Q9BXN1" class="uri">https://www.uniprot.org/uniprot/Q9BXN1</a></td>
</tr>
<tr class="odd">
<td align="left">Biglycan</td>
<td align="left">/wiki/Biglycan</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/P21810" class="uri">https://www.uniprot.org/uniprot/P21810</a></td>
</tr>
<tr class="even">
<td align="left">BMP binding endothelial regulator</td>
<td align="left">/wiki/BMP_binding_endothelial_regulator</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/Q8N8U9" class="uri">https://www.uniprot.org/uniprot/Q8N8U9</a></td>
</tr>
</tbody>
</table>
<p>In the event that we are unable to find their UniProt id, let’s for now consider those proteins <em>not so well-studied</em> and exclude them.</p>
</div>
<div id="uniprot-scraping" class="section level4">
<h4>UniProt scraping</h4>
<p>Our next target is the “Function” element on uniprot.org entry pages. An example:</p>
<p><img src="/images/finc.png" /><!-- --></p>
<p>Similarly to before, we’ll specify the xpath of the web-page to extract the content we are looking for.</p>
<pre class="r"><code># Exclude linkless proteins
wikitable &lt;- wikitable[!is.na(wikitable$uniprot),]

# Scrape UniProt, collect info: protein function and source organism
get_protein_function &lt;- function(wprot) {
    # print(paste(&quot;Searching&quot;, wprot[&quot;title&quot;]))
    
    # Follow UniProt url and read html
    up &lt;- read_html(wprot[&quot;uniprot&quot;])
    
    # Find function and organism nodes
    pfunction &lt;- html_nodes(up, xpath = &#39;//*[@id=&quot;function&quot;]/div[1]&#39;) %&gt;% html_text() %&gt;% trimws()
    organism &lt;- html_nodes(up, xpath = &#39;//*[@id=&quot;content-organism&quot;]&#39;) %&gt;% html_text()
    
    # If we don&#39;t find anything, set both to NA
    if(length(pfunction) == 0) pfunction &lt;- NA
    if(length(organism) == 0) organism &lt;- NA
    
    # Return as a list
    return (list(&quot;pfunction&quot; = pfunction,
                 &quot;organism&quot; = organism))
}

# Temporary list to hold both function and organism
pinfo &lt;- apply(wikitable, 1, get_protein_function)

# Convert lists to data frame columns
wikitable$protein_function &lt;- unlist(sapply(pinfo, FUN = function(x) x[&quot;pfunction&quot;][[1]], USE.NAMES = F, simplify = F))
wikitable$organism &lt;- unlist(sapply(pinfo, FUN = function(x) x[&quot;organism&quot;][[1]], USE.NAMES = F, simplify = F))

# Clean up text (remove anything after occurrence of linebreak, specific words...).
wikitable$protein_function &lt;- gsub(&#39;[0-9] Publications|\\.By similarity|\\.S|\\.s|  .*&#39;, &quot;&quot;, wikitable$protein_function)
wikitable$protein_function &lt;- gsub(&#39;(By similarity)|(PubMed:[0-9])|\r|\n|&lt;.*.&gt;|\\[.*.\\]|([0-9])&#39;, &quot;&quot;, wikitable$protein_function)</code></pre>
<p>Now let’s take a look at what species we have harvested!</p>
<pre class="r"><code>table(wikitable$organism)</code></pre>
<pre><code>## 
##                                             Homo sapiens (Human) 
##                                                               60 
## Pinctada fucata (Akoya pearl oyster) (Pinctada imbricata fucata) 
##                                                                1</code></pre>
<p>60 human proteins and 1 lone oyster.</p>
<p>:I</p>
<p>Sadly, we must exclude him.</p>
<pre class="r"><code># Convert to data.table
wikitable &lt;- as.data.table(wikitable)

# Keep only human proteins
wikitable &lt;- wikitable[organism == &quot;Homo sapiens (Human)&quot;,]

# Also, exclude rows where we could not find protein function
wikitable &lt;- wikitable[!is.na(protein_function),]

# And remove entries that do not contain a relevant description
wikitable &lt;- wikitable[!startsWith(protein_function, &quot;Complete GO annotation on QuickGO&quot;)]

# Write table to file so that we can use it later
fwrite(wikitable, &quot;wikitable.tsv&quot;, quote = F, sep = &#39;\t&#39;)

# Show entries that have short descriptions
kable(wikitable[nchar(protein_function) &lt; 70])</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="left">link</th>
<th align="left">uniprot</th>
<th align="left">protein_function</th>
<th align="left">organism</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Biglycan</td>
<td align="left">/wiki/Biglycan</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/P21810" class="uri">https://www.uniprot.org/uniprot/P21810</a></td>
<td align="left">May be involved in collagen fiber assembly</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
<tr class="even">
<td align="left">CCDC80</td>
<td align="left">/wiki/CCDC80</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/Q76M96" class="uri">https://www.uniprot.org/uniprot/Q76M96</a></td>
<td align="left">Promotes cell adhesion and matrix assembly</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
<tr class="odd">
<td align="left">CRISPLD2</td>
<td align="left">/wiki/CRISPLD2</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/Q9H0B8" class="uri">https://www.uniprot.org/uniprot/Q9H0B8</a></td>
<td align="left">Promotes matrix assembly</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
<tr class="even">
<td align="left">Decorin</td>
<td align="left">/wiki/Decorin</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/P07585" class="uri">https://www.uniprot.org/uniprot/P07585</a></td>
<td align="left">May affect the rate of fibrils formation.</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
<tr class="odd">
<td align="left">Extracellular matrix protein 2</td>
<td align="left">/wiki/Extracellular_matrix_protein_2</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/O94769" class="uri">https://www.uniprot.org/uniprot/O94769</a></td>
<td align="left">Promotes matrix assembly and cell adhesiveness</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
<tr class="even">
<td align="left">Matrilin-2</td>
<td align="left">/wiki/Matrilin-2</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/O00339" class="uri">https://www.uniprot.org/uniprot/O00339</a></td>
<td align="left">Involved in matrix assembly</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
<tr class="odd">
<td align="left">Osteoglycin</td>
<td align="left">/wiki/Osteoglycin</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/P20774" class="uri">https://www.uniprot.org/uniprot/P20774</a></td>
<td align="left">Induces bone formation in conjunction with TGF-beta- or TGF-beta-.</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
<tr class="even">
<td align="left">Tenomodulin</td>
<td align="left">/wiki/Tenomodulin</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/Q9H2S6" class="uri">https://www.uniprot.org/uniprot/Q9H2S6</a></td>
<td align="left">May be an angiogenesis inhibitor.</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
<tr class="odd">
<td align="left">VWA2</td>
<td align="left">/wiki/VWA2</td>
<td align="left"><a href="https://www.uniprot.org/uniprot/Q5GFL6" class="uri">https://www.uniprot.org/uniprot/Q5GFL6</a></td>
<td align="left">May be used as a serological marker for colon neoplasia.</td>
<td align="left">Homo sapiens (Human)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="conclusion---part-1" class="section level3">
<h3>Conclusion - Part 1</h3>
<p>So, what have we learnt? We can programmatically collect data from a website by specifying a url and a html xpath. In this case, we investigated the molecular function of some proteins and compiled this information into a dataframe. While it may seem like a tedious approach for a simple task, much of the code we have written can be used in future projects where we need to collect and clean data.</p>
<p>When we have meditated on today’s efforts, and finished studying the function of proteins, it is time to test our knowledge.</p>
<p><a href="/posts/2020-06-26-the-quiz-part-2.en.html">Go to Part 2</a></p>
</div>
